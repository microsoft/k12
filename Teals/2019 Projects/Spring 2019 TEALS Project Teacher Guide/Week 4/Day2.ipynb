{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Cognitive Hackathon: Week 4 - Teacher's Guide\n## Day 2\n\n## Overview\nExplore the meaning of data and how it impacts our endeavors. \n\n## Objectives\nComplete the project presentations. Talk over the next two days about data, what it is, where it comes from, how we try to interpret it, and its challenges.\n\n\n## Teacher Instruction: Complete Presentations (20 mins)\nHave the students wrap up their team presentations. Encourage class discussion. The teams will address these topics:\n\n* Project Goals\n* Cognitive Services\n* Data Sets\n* Project Output and Result\n* Conclusions\n* New Directions\n\n## Teacher Presentation: Data Presentation (40 mins)\nCognitive systems only work if the data they are given is good. Talk a bit about the responsibility we then have to ensure that data sets are complete. Sometimes we get results that we know to be incomplete and there are causes for this. Both we and cognitive systems can draw incorrect assumptions, interpreting data in ways that do not reflect reality. Talk about why that is. Lastly, as our systems are capable of digesting and interpreting more and more data, we are faced with moral decisions. Discuss the ethical implications of cognitive systems. \n\nEach topic should be followed by discussion:\n\n### Incomplete Input \nUnreliable results in an application are often due to incomplete input. Missing data can cause havoc in a analytical system. Missing data can come in the form of text, images, or other media that simply was not collected. Missing data may also take place when adequate data is collected but pieces of that data are not present or are unreadable, such as blurry or unrecognizeable images, or text that covers the correct topic but omits key words.\n\n### Incomplete Output\nThe cognitive services output over the past two weeks have demonstrated  how output can be incomplete. Vision cognitive services, for example, make educated guesses about what it is seeing, but if the image isn't sufficiently clear then the output will be off, not wrong exactly, but incomplete. A runner could be identified as a woman doing a sport outdoors, but not as a runner. A ballerina could be categorized as a woman doing a sport indoors, but not as a ballerina or even a dancer. These are examples of incomplete output. \n\n### Incorrect Assumptions\nCognitive systems must make judgement calls on their data, just like people do. Sometimes these calls are incorrect, such as guessing that a scuba diver is in the sky, simply because there's a lot of blue in the top of the background.\n\nExample: If you gathered all of the images from Instagram, counted all of the ones featuring dogs and cats and mapped those counts, that wouldn't account for all of the people who don't have Instagram, don't have public Instagrams, and/or don't post pictures of their pets online. So if you actually made an assumption about where dogs would be most likely to be adopted over cats based soley on this data gathering exercise, you may be not accounting for the fact that people who have cats simply don't post their pictures on Instagram.\n\n### Ethical Implications\nThere are many systems that have obvious ethical implications before cognitive came around, such as certain uses of surveillance, military, and data collection on individuals. With the gathering of vast amounts of data to feed cognitive systems, privacy becomes harder and harder to come by. Now that cognitive is here, the concerns are amplified, as computer-assisted decision-making moves into many more areas and industries. \n\nExample: Computer Vision cognitive systems are being used, for instance, to steer driverless cars and trucks. Imagine a situation where a driverless truck carrying a million dollars worth of fragile cargo. A small child walks into the road, and the driverless truck must decide whether to strike the child and protect its cargo or to turn so abruptly that it may roll and destroy a million dollars worth of merchandise. Cognitive machines will be faced with the decision of the measuring the value of human life, limb, and well-being against company profit and loss.\n\n## Summary\nThis class began a dialogue about the use and meaning of data."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.15",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 2,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}